{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Prompt-to-Image Generation\n",
    "\n",
    "To generate desired images using image generation models, it's crucial to accurately describe the image details in the prompt. However, creating detailed prompts without prior information can be challenging. To assist with this, we propose creative image prompt ideas based on user-provided styles and keywords through Multimodal LLM. This allows users to generate image prompts more intuitively and reduce the effort required for prompt writing.\n",
    "\n",
    "The image generation model used is [Amazon Titan Image Generator G1 v2](https://docs.aws.amazon.com/bedrock/latest/userguide/titan-image-models.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT_PATH = os.path.abspath(\"../../\")\n",
    "sys.path.append(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from common.aws.titan_image import BedrockTitanImage, ImageParams\n",
    "from common.utils.images import display_image, encode_image_base64_from_file\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from typing import List\n",
    "from common.aws.claude import BedrockClaude\n",
    "\n",
    "image_params = ImageParams()\n",
    "titanImageGen = BedrockTitanImage(\n",
    "    region='us-west-2',\n",
    "    modelId='amazon.titan-image-generator-v2:0'\n",
    ")\n",
    "\n",
    "keyword=\"olympic\",\n",
    "style=\"minimalist, simple, clean and abstract background image, and do not contain many patterns, logos, or letters.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = image_params.text_to_image(text=f\"{keyword}, {style}\")\n",
    "img = titanImageGen.generate_image(body)\n",
    "display_image(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Prompt\n",
    "\n",
    "This is the result of generating prompts for Image Generation from LLM. When you input style and keyword values, it suggests 3 image prompts based on that information.\n",
    "\n",
    "- `style`: desired mood or style\n",
    "- `keyword`: keywords for the image you want to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"You are an Assistant that creates prompts for generate background image by image generator model. The image that Human wants is written in <keyword>.\n",
    "Follow style guide in <style> and write three images creating prompts keeping it to 300 characters or less. Use this fomat without further explanation: \n",
    "<prompt>image prompt</prompt>\n",
    "\n",
    "<keyword>\n",
    "{keyword}\n",
    "</keyword>\n",
    "\n",
    "<style>\n",
    "{style}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "def extract_format(result_string):\n",
    "    pattern = r'<prompt>(.*?)</prompt>'\n",
    "    return re.findall(pattern, result_string)\n",
    "\n",
    "def get_prompt(keyword: str, style: str): \n",
    "    return PromptTemplate(\n",
    "                template=PROMPT,\n",
    "                input_variables=[\"keyword\", \"style\"]\n",
    "            ).format(keyword=keyword,\n",
    "                     style=style)\n",
    "\n",
    "def get_prompt_by_llm(prompt: str) -> List[str]:\n",
    "    claude = BedrockClaude()\n",
    "    res = claude.invoke_llm_response(prompt)\n",
    "    return extract_format(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = get_prompt(\n",
    "    keyword=keyword,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "image_prompts = get_prompt_by_llm(prompt)\n",
    "print(image_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt in image_prompts:\n",
    "    print(prompt)\n",
    "    body = image_params.text_to_image(text=prompt)\n",
    "    img = titanImageGen.generate_image(body)\n",
    "    display_image(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal LLM Prompt\n",
    "\n",
    "Titan Image Generator offers several options for creating new images based on reference images:\n",
    "\n",
    "- **Image Conditioning**: Generates images that match the layout and composition of the reference image while following text prompts. This may be limited to simply reconstructing existing images, restricting creative freedom.\n",
    "\n",
    "- **Color Guided Generation**: Reflects the color tone of the image by receiving reference colors through a reference image. While it reflects some color tones, it's difficult to reflect the mood or texture of the image.\n",
    "\n",
    "- **Image Variation**: Generates images that preserve the source image but transform the style and background. The range of variation is limited and there are constraints on the original image.\n",
    "\n",
    "While these methods are useful for reflecting specific attributes of reference images (such as color, layout, source image, etc.), they have limitations in generating completely new images that reflect creative and complex features due to the restricted range of variations. Using a Multimodal LLM to understand reference images and generate prompts for creating target images allows for more free and creative image prompt generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"You are an Assistant that creates prompts for generate background image by image generator model. The image that Human wants is written in <keyword>.\n",
    "            Write a images three creation prompts keeping it to 300 characters or less to maintain the style of a given image. Use this fomat without further explanation:\n",
    "            <prompt>image prompt</prompt>\n",
    "\n",
    "            <keyword>\n",
    "            {keyword}\n",
    "            </keyword>\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "def get_mm_prompt(keyword: str):\n",
    "    return PromptTemplate(\n",
    "                template=PROMPT,\n",
    "                input_variables=[\"keyword\"]\n",
    "            ).format(keyword=keyword)\n",
    "\n",
    "def get_prompt_by_mm_llm(prompt: str, image: str) -> List[str]:\n",
    "    claude = BedrockClaude()\n",
    "    res = claude.invoke_llm_response(text=prompt, image=image)\n",
    "    return extract_format(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = encode_image_base64_from_file(f\"{ROOT_PATH}/sample/house.jpg\", format=\"JPEG\")\n",
    "display_image(input_image)\n",
    "\n",
    "prompt = get_mm_prompt(keyword=keyword)\n",
    "image_prompts = get_prompt_by_mm_llm(prompt=prompt, image=input_image)\n",
    "print(image_prompts)\n",
    "\n",
    "for prompt in image_prompts:\n",
    "    print(prompt)\n",
    "    body = image_params.text_to_image(text=prompt)\n",
    "    img = titanImageGen.generate_image(body)\n",
    "    display_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c97182bcee1c5a46c75e12f527516848bb4d812af65bc6ddf5c082f318f5a83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
