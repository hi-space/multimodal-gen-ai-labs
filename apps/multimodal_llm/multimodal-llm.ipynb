{
    "cells": [{
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "\n",
                "ROOT_PATH = os.path.abspath(\"../../\")\n",
                "sys.path.append(ROOT_PATH)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from genai_kit.aws.claude import BedrockClaude\n",
                "from genai_kit.utils.images import encode_image_base64_from_file, display_image\n",
                "\n",
                "\n",
                "claude = BedrockClaude(\n",
                "    region=\"us-west-2\",\n",
                "    modelId=\"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Invoke Multimodal LLM with Bedrock API"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "encoded_base64 = encode_image_base64_from_file(file_path=\"./sample/food.jpg\")\n",
                "display_image(encoded_base64)\n",
                "\n",
                "res = claude.invoke_llm_response(text=\"How many tacos are there?\", image=encoded_base64)\n",
                "print(res)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Invoke Multimodal LLM with LangChain"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
                "from langchain.prompts import PromptTemplate\n",
                "from langchain.schema import (\n",
                "    HumanMessage,\n",
                "    SystemMessage,\n",
                ")\n",
                "\n",
                "def get_prompt(text: str = 'Describe this image', image: str = None):\n",
                "    content = []\n",
                "\n",
                "    if image:\n",
                "        content.append({\n",
                "            \"type\": \"image_url\",\n",
                "            \"image_url\": {\n",
                "                \"url\": f\"data:image/webp;base64,{image}\",\n",
                "            },\n",
                "        })\n",
                "\n",
                "    text = PromptTemplate(\n",
                "            template=\"\"\"Answer the user's questions, breaking them down into separate points.\n",
                "\n",
                "            Here is a question from Human:\n",
                "            <question>\n",
                "            {question}\n",
                "            </question>\n",
                "            \"\"\",\n",
                "            input_variables=[\"question\"]\n",
                "        ).format(question=text)\n",
                "\n",
                "    content.append({\n",
                "        \"type\": \"text\",\n",
                "        \"text\": text\n",
                "    })\n",
                "\n",
                "    messages = [\n",
                "        SystemMessage(content=\"You are a helpful assistant.\"),\n",
                "        HumanMessage(\n",
                "            content=content\n",
                "        )\n",
                "    ]\n",
                "\n",
                "    return messages\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# streaming response\n",
                "callback = StreamingStdOutCallbackHandler()\n",
                "chat = claude.get_chat_model(callback=callback)\n",
                "\n",
                "prompt = get_prompt(text=\"How many tacos are there?\", image=encoded_base64)\n",
                "res = await chat.ainvoke(prompt)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.12"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "2c97182bcee1c5a46c75e12f527516848bb4d812af65bc6ddf5c082f318f5a83"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}